# Алгоритм работы ComfyUIGen

## 1. Общее описание
Проект представляет собой генератор визуальных новелл с использованием AI для генерации текста и изображений.

## 2. Основные компоненты
- Frontend (HTML + JS): Интерфейс пользователя
- Backend (Python/Flask): Управление логикой и API
- Ollama: Генерация текста
- ComfyUI: Генерация изображений
- WebSocket: Коммуникация между frontend и backend

## 3. Пошаговый алгоритм работы

### 3.1 Инициализация системы
1. **Запуск сервера** (`main.py`)
   - Инициализация Flask приложения
   - Настройка WebSocket соединения
   - Загрузка конфигурации ComfyUI

2. **Подготовка внешних сервисов**
   - Проверка доступности Ollama
   - Проверка доступности ComfyUI
   - Инициализация очередей сообщений

### 3.2 Процесс генерации истории
1. **Начало сессии** (`app/api/routes/story.py`)
   - Создание новой сессии
   - Инициализация WebSocket соединения
   - Отправка начального состояния на frontend

2. **Генерация текста** (`app/services/ollama/story_generator.py`)
   - Получение контекста истории
   - Формирование промпта для Ollama
   - Генерация текста
   - Обработка и форматирование результата

3. **Генерация изображений** (`app/services/comfy/image_generator.py`)
   - Анализ текста для создания промпта
   - Подготовка workflow для ComfyUI
   - Отправка задачи на генерацию
   - Получение и обработка результата

4. **Коммуникация с frontend** (`static/js/main.js`)
   - Получение сообщений через WebSocket
   - Отображение текста и изображений
   - Обработка пользовательского ввода
   - Отправка выборов пользователя на backend

### 3.3 Обработка пользовательского ввода
1. **Выбор опций**
   - Получение выбора от пользователя
   - Обновление контекста истории
   - Генерация нового текста и изображений

### 3.4 Обработка ошибок
1. **Сетевые ошибки**
   - Переподключение WebSocket
   - Восстановление состояния сессии

2. **Ошибки генерации**
   - Повторные попытки
   - Fallback варианты

### 3.5 Управление памятью и ресурсами
1. **Очистка GPU памяти**
   - Автоматическая выгрузка моделей при превышении порога памяти
   - Принудительная очистка после каждой генерации
   - Перезапуск сервисов при критической нагрузке

2. **Очередь изображений**
   - Буферизация запросов на генерацию
   - Приоритезация по времени и статусу сессии
   - Ограничение количества одновременных генераций

### 3.6 Процесс перевода промптов
1. **Перевод текста в промпт**
   - Анализ сгенерированного текста
   - Извлечение ключевых описаний
   - Формирование промпта для изображения

2. **Обработка параллельных запросов**
   - Очередь запросов на перевод
   - Кэширование частых промптов
   - Fallback на базовые промпты при ошибках

### 3.7 Параллельная обработка
1. **Многопользовательский режим**
   - Изоляция сессий пользователей
   - Отдельные контексты для каждой истории
   - Балансировка нагрузки между сессиями

2. **Параллельная генерация**
   - Асинхронная генерация текста и изображений
   - Приоритезация текстовой генерации
   - Отложенная загрузка изображений

## 4. Конфигурационные файлы

### 4.1 Конфигурация Ollama
**Файл:** `config/ollama_config.py`
- `OLLAMA_CONFIG` - основные настройки
  - base_url - адрес сервера
  - model - модель для генерации
  - generation_params - параметры генерации текста
  - connection - настройки подключения
  - context - настройки контекста
  - history - настройки истории
- `ERROR_HANDLING` - обработка ошибок
  - max_retries - максимальное число повторов
  - fallback_model - резервная модель
  - timeout_settings - настройки таймаутов
  - error_prompts - шаблоны сообщений об ошибках

### 4.2 Конфигурация ComfyUI
**Файл:** `config/comfy_config.py`
- `ComfyUIConfig` - класс конфигурации
  - Сетевые настройки (host, port)
  - default_workflow - базовый воркфлоу
    - KSampler - параметры сэмплера
    - CheckpointLoaderSimple - загрузка модели
    - VAELoader - настройки VAE
    - CLIPTextEncode - кодирование текста
    - EmptyLatentImage - настройки изображения
- `MODEL_PATHS` - пути к моделям
  - checkpoints_dir - директория с чекпоинтами
  - vae_dir - директория с VAE моделями
  - lora_dir - директория с LoRA моделями
- `RESOURCE_LIMITS` - ограничения ресурсов
  - max_batch_size - максимальный размер батча
  - max_resolution - максимальное разрешение
  - memory_limit - лимит использования памяти

### 4.3 Конфигурация Story Generator
**Файл:** `app/services/ollama/story_generator.py`
- `ModelManager` - управление моделями
  - Параметры GPU
  - Управление памятью
  - Загрузка/выгрузка моделей

## 5. Точки расширения
1. Добавление новых моделей для генерации текста
2. Кастомизация workflow ComfyUI
3. Добавление новых типов контента
4. Расширение пользовательского интерфейса
